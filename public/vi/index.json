[
{
	"uri": "//localhost:1313/vi/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "The focus of this workshop is to educate you on how to use Guardrails for Amazon Bedrock and help you understand how to apply them within a practical scenario.\nThroughout the session, you’ll gain hands-on experience in configuring and testing guardrails, learn how to align them with your organization’s responsible AI policies, and explore how they enhance safety, compliance, and user trust in generative AI applications.\nBy the end of this workshop, you\u0026rsquo;ll be equipped with the knowledge to:\nCreate and manage custom guardrails tailored to different use cases\nDefine and enforce denied topics\nConfigure content filters to block harmful or inappropriate content\nUnderstand how guardrails integrate with foundation models across Amazon Bedrock\nApply guardrails effectively in real-world AI-powered applications\nPricing for This Workshop "
},
{
	"uri": "//localhost:1313/vi/3-building-trustworthy-ai-with-amazon-bedrock-guardrails/1-overview/",
	"title": "Overview",
	"tags": [],
	"description": "",
	"content": "1 - Define the Guardrails Identify the specific needs of your customer service, like topics to avoid and content to filter. For instance, blocking discussions on investment advice in a tech support chat.\n2 - Configure Content Filters Set thresholds for different content categories based on the level of strictness required. Below are the thresholds that Amazon Bedrock Guardrails provide for both prompts and respnoses.\nHate: Describes input prompts and model responses that discriminate, criticize, insult, denounce, or dehumanize a person or group on the basis of an identity (such as race, ethnicity, gender, religion, sexual orientation, ability, and national origin).\nInsults: Describes input prompts and model responses that includes demeaning, humiliating, mocking, insulting, or belittling language. This type of language is also labeled as bullying.\nSexual: Describes input prompts and model responses that indicates sexual interest, activity, or arousal using direct or indirect references to body parts, physical traits, or sex.\nViolence: Describes input prompts and model responses that includes glorification of or threats to inflict physical pain, hurt, or injury toward a person, group or thing.\nMisconduct: Describes input prompts and model responses that seeks or provides information about engaging in criminal activity, or harming, defrauding, or taking advantage of a person, group or institution.\nPrompt Attack: Describes user prompts intended to bypass the safety and moderation capabilities of a foundation model (FM) in order to generate harmful content (also known as jailbreak), and ignore and override instructions specified by the developer (referred to as prompt injection). 3 - Add Denied Topics Add denied topics based on what was defined in step 1. Guardrails can be configured with a set of denied topics that are undesirable in the context of your AI application. You can define up to 30 denied topics. Input prompts and model completions will be evaluated against each of these denied topics. If one of the denied topics is detected, the blocked message configured as part of the guardrail will be returned to the user. 4 - Implement Guardrails Enforce Guardrails within Amazon Bedrock\n5 - Test and Fine tune Check if the guardrails are working properly through test cases and inputs.\n6 - Enforce Guadrails on Agent Regularly review the performance of Guardrails and make necessary adjustments to the configurations.\nLet us get started in the next lesson with creating our Guardrails.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Building Trustworthy AI with Amazon Bedrock Guardrails",
	"tags": [],
	"description": "",
	"content": "Building Trustworthy AI with Amazon Bedrock Guardrails Workshop Overview Guardrails for Amazon Bedrock Objectives of the Workshop In this workshop, you\u0026rsquo;ll explore how to set up and configure Amazon Bedrock Guardrails through a hands-on sample scenario.\nAmazon Bedrock Guardrails empowers you to establish policies that help protect your generative AI applications from producing or interacting with unsafe content. With Guardrails, you can tailor content moderation rules to meet the specific needs of your application.\nYou’ll be able to configure two key types of safeguards:\nDenied Topics: Specify topics that should be restricted in your application. For instance, a virtual assistant for online banking can be configured to avoid giving investment advice.\nContent Filters: Set sensitivity thresholds to detect and block potentially harmful content in categories such as hate speech, insults, sexually explicit material, and violence.\n"
},
{
	"uri": "//localhost:1313/vi/3-building-trustworthy-ai-with-amazon-bedrock-guardrails/2-creating-the-guardrail/",
	"title": "Creating The Guardrail",
	"tags": [],
	"description": "",
	"content": " Go to Amazon Bedrock console, then click on Safeguards \u0026gt; Guardrails from the left pane Click on Create guardrails Enter the following details and click Next "
},
{
	"uri": "//localhost:1313/vi/2-getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " To get started, go to AWS Console. Go to Amazon Bedrock console. Click on the hamburger icon to expand the left panel menu and click on Model access On the Model access screen, click on top right button Enable Specific Models. You can choose any text based model you prefer for the purpose of this workshop.\nAs an example we are choosing Mistral 7B Instruct part of Mistral AI.\nAfter selecting your desired text model, click on Next and on the next page click on Submit You will find that the model access has been granted "
},
{
	"uri": "//localhost:1313/vi/3-building-trustworthy-ai-with-amazon-bedrock-guardrails/",
	"title": "Building Trustworthy AI with Amazon Bedrock Guardrails",
	"tags": [],
	"description": "",
	"content": "What is Amazon Bedrock? Amazon Bedrock is a fully managed service that enables you to build and scale generative AI applications quickly and securely, starting with a foundation model (FM) of your choice. It provides access to a variety of leading FMs from top AI providers through a simple API, without the need to manage infrastructure.\nA key feature of Amazon Bedrock is Guardrails, which allows organizations to implement safeguards—referred to as guardrails—that monitor and control both user inputs and AI-generated outputs. These safeguards help ensure that the AI behavior aligns with your organization’s policies and ethical standards. Guardrails are model-agnostic and can be integrated across various use cases and applications.\nWhat is Guardrails for Amazon Bedrock? Guardrails for Amazon Bedrock is a powerful feature that enables you to establish safety controls within your generative AI applications. Guardrails help filter, block, or manage content that may be considered harmful, inappropriate, or misaligned with your organization’s policies.\nThese safeguards work across different foundation models and are designed to ensure responsible use of AI by checking both user inputs and AI outputs. In future updates, Guardrails will also support automatic redaction of personally identifiable information (PII)—further enhancing content safety and privacy.\nWith Guardrails, you can configure and enforce policies such as:\nDenied Topics: Specify topics that are not allowed within your application. Example: A virtual banking assistant can be restricted from giving investment advice.\nContent Filters: Set thresholds to detect and filter content related to: Hate speech, Insults, Sexual content, Violence,\u0026hellip;\n"
},
{
	"uri": "//localhost:1313/vi/3-building-trustworthy-ai-with-amazon-bedrock-guardrails/3-configure-the-threshold/",
	"title": "Configure The Threshold",
	"tags": [],
	"description": "",
	"content": "Configure content filters by adjusting the degree of filtering to detect and block harmful user inputs and model responses that violate your usage policies.\nBelow are the options that are available:\nHate: Describes input prompts and model responses that discriminate, criticize, insult, denounce, or dehumanize a person or group on the basis of an identity (such as race, ethnicity, gender, religion, sexual orientation, ability, and national origin).\nInsults: Describes input prompts and model responses that includes demeaning, humiliating, mocking, insulting, or belittling language. This type of language is also labeled as bullying.\nSexual: Describes input prompts and model responses that indicates sexual interest, activity, or arousal using direct or indirect references to body parts, physical traits, or sex.\nViolence: Describes input prompts and model responses that includes glorification of or threats to inflict physical pain, hurt, or injury toward a person, group or thing.\nMisconduct: Describes input prompts and model responses that seeks or provides information about engaging in criminal activity, or harming, defrauding, or taking advantage of a person, group or institution.\nPrompt Attack: Describes user prompts intended to bypass the safety and moderation capabilities of a foundation model (FM) in order to generate harmful content (also known as jailbreak), and ignore and override instructions specified by the developer (referred to as prompt injection).\nFor the purposes of this workshop, we will configure Filter Strengths as HIGH Once done click on Next\n"
},
{
	"uri": "//localhost:1313/vi/4-creating-denied-topics/",
	"title": "Creating Denied Topics",
	"tags": [],
	"description": "",
	"content": "Guardrails can be configured with a set of denied topics that are undesirable in the context of your generative AI application. For example, a bank may want their AI assistant to avoid any conversation related to investment advice or engage in conversations related to cyrptocurrencies.\nYou can define up to 30 denied topics. Input prompts and model completions will be evaluated against each of these denied topics. If one of the denied topics is detected, the blocked message configured as part of the guardrail will be returned to the user.\nDenied topics can be defined by providing a natural language definition of the topic along with a few optional example phrases of the topic. The definition and example phrases are used to detect if an input prompt or a model completion belongs to the topic.\nIn the following section we will configure three types of Denied topics for medical advice, financial advice and political advice.\n"
},
{
	"uri": "//localhost:1313/vi/4-creating-denied-topics/1-denied-topic---financial-advice/",
	"title": "Denied Topic - Financial Advice",
	"tags": [],
	"description": "",
	"content": " On the Add Denied Topics Section - Click Add Denied Topic Enter the following information into the Guardrail Name: Financial Advice\nDefinition For Topic: Discussions that involve providing guidance, recommendations, or suggestions related to managing, investing, or handling finances, investments, or assets.\nSample Phrases:\nCan you suggest some good stocks to invest in right now ? What\u0026rsquo;s the best way to save for retirement ? Should I put my money in a high-risk investment ? How can I maximize my returns on investments ? Is it a good time to buy real estate ? Once field are completed, click on Confirm to create the denied topic "
},
{
	"uri": "//localhost:1313/vi/4-creating-denied-topics/3-denied-topic---medical-advice/",
	"title": "Denied Topic - Medical Advice",
	"tags": [],
	"description": "",
	"content": " On the Add Denied Topics Section - Click Add Denied Topic Enter the following information into the Guardrail Name: Political Advice\nDefinition For Topic: Conversations that express views, opinions, or endorsements related to political parties, political ideologies, elections, or political figures.\nSample Phrases:\nWhat\u0026rsquo;s your stance on the current government policies ? Do you support party X or Y in the upcoming election ? Can you tell me which political party is better ? What do you think about the new policy introduced by the president ? Should I vote for this candidate ? Click on Confirm to create the denied topic "
},
{
	"uri": "//localhost:1313/vi/4-creating-denied-topics/2-denied-topic---political-advice/",
	"title": "Denied Topic - Political Advice",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/5-add-filters-to-guardrail/",
	"title": "Add filters to Guardrail",
	"tags": [],
	"description": "",
	"content": "Nội dung Khởi tạo Cognito User pool Kiểm tra Cognito User pool Tài liệu tham khảo Amazon Cognito - Control access to REST APIs using Amazon Cognito user pools as an authorizer "
},
{
	"uri": "//localhost:1313/vi/6-testing-guardrail/",
	"title": "Testing Guardrail",
	"tags": [],
	"description": "",
	"content": "Khởi tạo DynamoDB Truy cập vào AWS Management Console\nTìm DynamoDB Chọn DynamoDB Ở giao diện Dashboard của DynamoDB\nChọn Create table Ở giao diện Create table\nTable name nhập FCJ-DynamoDB\nPartition key nhập id chọn string\nSort key nhập name chọn string Table settings để mặc định\nKéo xuống và chọn Create table Tài liệu tham khảo Working with tables and data in DynamoDB "
},
{
	"uri": "//localhost:1313/vi/7-apply-guardrails-to-agent/",
	"title": "Apply Guardrails to Agent",
	"tags": [],
	"description": "",
	"content": "Triển khai Lambda function Truy cập vào AWS Management Console\nTìm Lambda Chọn Lambda Trong giao diện Lambda\nChọn Create a function Trong giao diện Create function\nChọn Author from scratch\nFunction name nhập FCJ-LambdaFunction\nRuntime chọn Python 3.9\nArchitecture chọn x86_64\nKéo xuống và chọn Create function Sau khi tạo bạn sẽ thấy giao diện sau đây Nhập Source code cho Lambda Function\nChọn Code Dán code vào import boto3\rimport uuid\r# Tạo tài nguyên DynamoDB\rdynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;)\r# Đặt tên bảng DynamoDB\rtable = dynamodb.Table(\u0026#39;FCJ-DynamoDB\u0026#39;)\r# Tạo một SNS Client\rclient_sns = boto3.client(\u0026#39;sns\u0026#39;)\r# Hàm này sẽ được kích hoạt bởi API Gateway\rdef lambda_handler(event, context):\rtry:\r# Kiểm tra sự tồn tại của các key bắt buộc\rrequired_keys = [\u0026#39;name\u0026#39;, \u0026#39;email\u0026#39;, \u0026#39;subject\u0026#39;, \u0026#39;description\u0026#39;]\rfor key in required_keys:\rif key not in event:\rraise KeyError(f\u0026#34;Missing required key: {key}\u0026#34;)\r# Tạo một ID người dùng\rid = str(uuid.uuid4())\r# Gửi tin nhắn đến SNS\rhandle_sns(id, event)\r# Lưu trữ dữ liệu vào DynamoDB\rstatusCode = handle_dynamo_db(id, event)\rreturn {\r\u0026#39;statusCode\u0026#39;: statusCode,\r}\rexcept KeyError as ke:\rreturn {\r\u0026#39;statusCode\u0026#39;: 400,\r\u0026#39;body\u0026#39;: json.dumps(f\u0026#34;Missing required key: {str(ke)}\u0026#34;)\r}\rexcept Exception as e:\rreturn {\r\u0026#39;statusCode\u0026#39;: 500,\r\u0026#39;body\u0026#39;: json.dumps(\u0026#39;Error occurred: \u0026#39; + str(e))\r}\r# Gửi một tin nhắn đến SNS\rdef handle_sns(id, event):\rtry:\rsns_message = f\u0026#34;\u0026#34;\u0026#34;\rYou got a new Message from https://workshop.conglyblog.id.vn\rThe message is as follows\rid : {id}\rName : {event[\u0026#39;name\u0026#39;]}\remail : {event[\u0026#39;email\u0026#39;]}\rMessage : {event[\u0026#39;description\u0026#39;]}\rSubject : {event[\u0026#39;subject\u0026#39;]}\r\u0026#34;\u0026#34;\u0026#34;\rclient_sns.publish(\r# Thay đổi ARN với ARN của SNS của bạn\rTopicArn=\u0026#39;arn:aws:sns:ap-southeast-1:336760284039:FCJ-SNSTopic\u0026#39;,\rMessage=sns_message,\rSubject=event[\u0026#39;subject\u0026#39;]\r)\rexcept KeyError as ke:\rprint(f\u0026#34;Key error: {ke}\u0026#34;)\rraise\rexcept Exception as e:\rprint(f\u0026#34;An error occurred when sending SNS: {e}\u0026#34;)\rraise\r# Thêm một mục vào bảng DynamoDB\rdef handle_dynamo_db(id, event):\rtry:\rresponse = table.put_item(\rItem={\r\u0026#39;id\u0026#39;: id,\r\u0026#39;name\u0026#39;: event[\u0026#39;name\u0026#39;],\r\u0026#39;email\u0026#39;: event[\u0026#39;email\u0026#39;],\r\u0026#39;subject\u0026#39;: event[\u0026#39;subject\u0026#39;],\r\u0026#39;description\u0026#39;: event[\u0026#39;description\u0026#39;],\r}\r)\rreturn response[\u0026#39;ResponseMetadata\u0026#39;][\u0026#39;HTTPStatusCode\u0026#39;]\rexcept Exception as e:\rprint(f\u0026#34;An error occurred when writing to DynamoDB: {e}\u0026#34;)\rraise Thay đổi tên miền này của đoạn code trên: \u0026ldquo;You got a new Message from https://workshop.conglyblog.id.vn\u0026rdquo; thành tên miền của bạn.\nChọn Deploy Cấu hình IAM Roles cho Lambda\nChọn Configuration Chọn Permissions Chuyển hướng đến IAM Roles Trong giao diện Permissions\nChọn Add permissions\nChọn Attach policies Tìm SNS\nChọn AmazonSNSFullAccess Tiếp tục, tìm DynamoDB\nChọn AmazonDynamoDBFullAccess\nChọn Add permissions Tài liệu tham khảo Building Lambda functions with Python "
},
{
	"uri": "//localhost:1313/vi/8-test-guardrails-with-the-agent/",
	"title": "Test Guardrails with the Agent",
	"tags": [],
	"description": "",
	"content": "Nội dung Tạo API Tạo Method Tạo Authorizers Tạo Stages Thiết lập cấu hình CORS Cấu hình API Tài liệu tham khảo API Gateway REST APIs "
},
{
	"uri": "//localhost:1313/vi/9-clean-resource/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Chúng ta sẽ tiến hành các bước sau để xóa các tài nguyên chúng ta đã tạo trong bài thực hành này.\nXóa S3 Truy cập vào giao diện của S3\nChọn Buckets\nChọn Bucket name bạn đã tạo\nChọn Delete Trong giao diện Delete bucket\nChọn Empty bucket Trong giao diện Empty bucket\nNhập permanently delete vào mục confirm Chọn Empty Sau khi Empty thành công\nChọn Bucket Chọn lại Bucket name mà bạn muốn xóa Chọn Delete Trong giao diện Delete bucket\nCopy Bucket name mà bạn đã tạo Dán vào mục confirm Chọn Delete bucket Xóa Cloudfront Truy cập vào giao diện của Cloudfront Chọn Distributions Chọn Distribution ID bạn đã tạo Chọn Disable Đợi khoảng vài phút, sau đó chọn Delete Xóa Route 53 Truy cập vào giao diện của Route 53 Chọn Hosted zones Chọn Hosted zone name bạn đã tạo Chọn Delete Trong giao diện Delete hosted zone Nhập delete vào mục confirm Chọn Delete Xóa SNS Truy cập vào giao diện của SNS Chọn Topics Chọn Topic name bạn đã tạo Chọn Delete Trong giao diện Delete topic Nhập delete me vào mục confirm Chọn Delete Xóa Cognito Truy cập vào giao diện của Cognito Chọn User pools Chọn User pool name bạn đã tạo Chọn Delete Trong giao diện Delete user pool Chọn Delete Cognito domain fcj06f03 that you assigned và Deactivate deletion protection Nhập tên user pool của bạn vào mục confirm Chọn Delete Xóa DynamoDB Truy cập vào giao diện của DynamoDB Chọn Tables Chọn Table name bạn đã tạo Chọn Delete Trong giao diện Delete table Chọn Delete all CloudWatch alarms for FCJ-DynamoDB. Nhập confirm vào mục confirm Chọn Delete Xóa Lambda Truy cập vào giao diện của Lambda Chọn Functions Chọn Function name bạn đã tạo Chọn Actions Chọn Delete Trong giao diện Delete functions Nhập delete vào mục confirm Chọn Delete Xóa API Gateway Truy cập vào giao diện của API Gateway Chọn APIs Chọn API name bạn đã tạo Chọn Delete Trong giao diện Delete API Nhập confirm vào mục confirm Chọn Delete Xóa WAF Truy cập vào giao diện của WAF Chọn Web ACLs Chọn Web ACL name bạn đã tạo Chọn Associated AWS resources Chọn Disassociate Trong giao diện Disassociate Nhập remove vào mục confirm Disassociation Chọn Disassociate Vào lại Web ACLs Chọn Web ACL name bạn đã tạo Chọn Delete Trong giao diện Delete Nhập delete vào mục confirm Chọn Delete "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]